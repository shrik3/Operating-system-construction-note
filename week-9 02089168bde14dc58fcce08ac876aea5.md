# week-9

# **week-9**

- Course: OSC
- [Materials:](https://os.inf.tu-dresden.de/Studium/OSC/SS2022/L09-Threadsync.pdf)

# Motivation

## EVP

### Threads <f> and <g>

![Untitled](week-9%2002089168bde14dc58fcce08ac876aea5/Untitled.png)

- Problem: Buffer accesses can overlap
- **differences vs before**
    - Before :Synchronization of accesses by control flows from **different levels**
        - 
    - Now: Synchronization of accesses by control flows
    from the **same level**

# Control-flow Level Model with Threads

- Control-Flow Level Model: so far
    
    ![屏幕截图 2022-05-06 165046.png](week-9%2002089168bde14dc58fcce08ac876aea5/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE_2022-05-06_165046.png)
    
    - ctrl flows can be intertupted by ctrl flows on lower level(bigger Nr), never be interrupted by ctrl flows on higher level, and sequentialized by ctrl flows on the same level.
    - Control flows can switch levels by special operations (here: modifying the status register)
    - no longer works with preemption thread
- CTRL flow level model : new
    - Interrupt anytime by ctrl flow on Lg.         (f < g)
    - Never interrupted by ctrl floe on Le.         (e ≤ f)
    - Sequentialized with other ctrl flow on Lf  (f > 0)
    - Preempted by other ctrl flow on Lf.           (f = 0)

![Untitled](week-9%2002089168bde14dc58fcce08ac876aea5/Untitled%201.png)

# Thread Synchronization

- Thread can be preemptes by any thread at any time
- Thread Synchronization: Overview
    - Goal (for the user):
    Coordination of resource accesses
        - Mutex : Coordinating exclusive access reusable resources
        - Semaphpre : Interacting with / coordinating consumable resources

### Mutex – Mutual Exclusion

- Correctness condition : At every point in time, there is at maximum one thread in the critical section.
- **Mutex: with Busy Waiting**
    - **Assessment**
        - PROs
            - Maintains consistency, satisfies correctness condition
            - Synchronization without involving the OS
        - CONs
            - Busy waiting wastes a lot of CPU time

```cpp
// __atomic_test_and_set is a gcc builtin for
// (CPU specific) test-and-set
class SpinningMutex {
 char locked;  //(0=free, 1=locked)
public:
 SpinningMutex() : locked (0) {}
 void lock(){
 while (__atomic_test_and_set(
 &locked, __ATOMIC_RELAXED))
 ;
 }
 void unlock() {
 locked = 0;
 }
};
```

```cpp
lock:
		 mov $1,%dl
L2:  
		 mov %edx,%eax
		 xchg %al,(%rdi)
		 test %al,%al   // if old value of lock is 1 continue loop
		 jne L2
		 ret
unlock:
		 movb $0, (%rdi)
		 ret
```

- **Mutex: with “Hard Synchronization”**
    
    ```cpp
    class HardMutex {
    public:
     void lock(){
     forbid(); // disable multitasking
     }
     void unlock(){
     permit(); // enable multitasking
     }
    };
    ```
    
    ```cpp
    void forbid(){
     enter();
    }
    void permit(){
     leave();
    }
    ```
    
    - Necessitates a way to disable preemption
    - **Assessment**
        - PROs
            - Maintains consistency, satisfies correctness condition
            - Simple to implement
        - CONs
            - Broadband effect
                - Across-the-board delay of all threads (and potentially even epilogues!)
            - Priority violation
                - delay control flows with higher priority
            - Pessimistic
                - We put up with the disadvantages, although the collision probability is very low.
        - Thread synchronization on epilogue level has many disadvantages. It is, however, appropriate for very short, seldomly entered critical sections – or if we need to synchronize with epilogues anyways.

### Passive Waiting

- Better approach: Exclude thread from CPU scheduling as long as the mutex is locked
- Mutex: with Passive Waiting
    - Threads can “wait passively” for an event
        - Wait passively → be excluded from CPU scheduling
        - New thread state: **waiting (for an event)**
    - Occurrence of an event triggers leaving the waiting state
        - Thread is included in CPU scheduling
        - Thread state: **ready**
- Necessary abstractions:
    - Scheduler operations: block(), wakeup()
    - Synchronization object: **Waitingroom**
        - Synchronization object: Waitingroom
        
        ![Untitled](week-9%2002089168bde14dc58fcce08ac876aea5/Untitled%202.png)
        
- Scheduler operations
    - **block(Waitingroom& w)**
        - enqueue active thread (caller) in queue of synchronization object w
        - activate another thread (from ready list)
    - **wakeup(Customer& t)**
        - enqueue t in ready list
- Waitingroom operations
    - enqueue and dequeue.
    
    ```cpp
    class WaitingMutex : public Waitingroom {
     char locked;
    public:
     WaitingMutex() : locked(0) {}
     void lock() {
     while (__atomic_test_and_set(&locked, __ATOMIC_RELAXED))
     scheduler.block(*this);
     }
     void unlock() {
     locked = 0;
     // fetch possibly waiting thread and wake it up
     Customer *t = dequeue();
     if (t)
     scheduler.wakeup(*t); 
    //still test if lock free , if not, block again
     }
    };
    ```
    
    - Why not wake all threads up?
        - all threads will been enqueued and test their lock statements, those thread with their lock statement locked while they were setting in waitting room, which means they are still been locked. so they will been blocked again except the first one.
    - Do we really need TAS here?
        - bigger Problem : lock() and unlock() are critical sections themselves and Atomic TAS cannot solve it
            - we figure out lock is locked, enter loop body, just before we call block, there is context switch, other thread unlock the lock, at some point we go back and still enter block
                - we block ourself althought the lock is free.
                - possible block and never wakeup
    - approach:
    
    ```cpp
    class WaitingMutex : public Waitingroom {
     char volatile locked;
    public:
     WaitingMutex() : locked(0) {}
     void lock() {
    	 **mutex.lock();**
    	 while (locked == 1)
    	 scheduler.block(*this);
    	 locked = 1;
    	 **mutex.unlock();**
     }
     void unlock() {
    	 **mutex.lock();**
    	 locked = 0;
    	 // fetch possibly waiting thread and wake it up
    	 Customer *t = dequeue();
    	 if (t) scheduler.wakeup(*t);
    	** mutex.unlock();**
     }
    };
    ```
    
    - still this wattingmutex is recursive.
    - spinmutex works here
    - WORKS WITH A HARDMUTEX
        - protect lock() and unlock() on the epilogue level
    
    ```cpp
    class WaitingMutex : public Waitingroom {
     char volatile locked;
    public:
     WaitingMutex() : locked(0) {}
     void lock() {
     **enter();**
     while (locked == 1)
     scheduler.block(*this);
     locked = 1;
     **leave();**
     }
     void unlock() {
     **enter();**
     locked = 0;
     // fetch possibly waiting thread and wake it up
     Customer *t = dequeue();
     if (t) scheduler.wakeup(*t);
     **leave();**
     }
    };
    ```
    

![Untitled](week-9%2002089168bde14dc58fcce08ac876aea5/Untitled%203.png)

![Untitled](week-9%2002089168bde14dc58fcce08ac876aea5/Untitled%204.png)

### Semaphore

- semaphore := synchronization object + counter
- prolaag(), P(), wait(), down(), acquire(), pend()
    - if counter > 0, decrease counter
    - if counter ≤ 0, wait until counter > 0 and retry
- verhoog(), V(), signal(), up(), release(), post()
    - increase counter
    - if counter = 1, wake up possibly waiting thread
- Semaphore vs. Mutex
    - Mutex is often understood as a two-valued semaphore
        - – Mutex Semaphore with initial counter value 1
        - lock() → P(), unlock() → V()
    - However, the semantics are different
        - A locked mutex (implicitly or explicitly) has an owner
            - Only this owner may call unlock()
            - Mutex implementations e.g. on Linux or Windows check this.
        - A mutex can (usually) also be locked recursively.
            - Internal counter: The same thread may call lock() multiple times; after a matching number of unlock() calls, the mutex is unlocked again.
        - In contrast, a semaphore can be incremented or decremented by any thread

# Synchronization Objects on Windows

- Structure for a fast mutex in user mode [8]
- Internally uses an Event (kernel object) in case we must wait
- Lazy (on-demand) Event creation

# Summary

[Task-6](week-9%2002089168bde14dc58fcce08ac876aea5/Task-6%209352c222cd8a42189e39140bd6dec18f.md)