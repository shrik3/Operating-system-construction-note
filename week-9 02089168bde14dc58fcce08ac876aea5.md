# week-9

# **week-9**

- Course: OSC
- [Materials:](https://os.inf.tu-dresden.de/Studium/OSC/SS2022/L09-Threadsync.pdf)

# Motivation

## EVP

### Threads <f> and <g>

- preemptive round robin scheduling

![Untitled](week-9%2002089168bde14dc58fcce08ac876aea5/Untitled.png)

![Untitled](week-9%2002089168bde14dc58fcce08ac876aea5/Untitled%201.png)

- Problem: Buffer accesses can overlap, inconsistency of the data structure
- **differences vs before(L05)**
    - Before :Synchronization of accesses by control flows from **different levels**
        - State was logically assigned to one specific level
            - e.g buf[] on epilogue level
        - Synchronization either “from above” (hard) or “from below” (non-blocking)
        - Implicit sequentialization within the same level
            - all epilogs are synchronized
    - Now: Synchronization of accesses by control flows from the **same level**
        - Threads can be preempted by other threads at any time

# Control-flow Level Model with Threads

- Control-Flow Level Model: so far
    
    ![屏幕截图 2022-05-06 165046.png](week-9%2002089168bde14dc58fcce08ac876aea5/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE_2022-05-06_165046.png)
    
    - Interrupted anytime by ctrl flow on Lg.         (f < g)
    - Never interrupted by ctrl flow on Le.         (e ≤ f)
    - Sequentialized with other ctrl flow on Lf
    - Control flows can switch levels by special operations (here: modifying the status register)
        - or by enter and leave
    - By supporting preemptive threads we cannot sustain this
    assumption any longer
        - no run to completion
            - preempted before its completion
        - State accesses (from the same level) are not implicitly synchronized by sequentialized thread on the same level
        - for all level, usually for the appl level(L0)
- CTRL flow level model : new
    - Interrupted anytime by ctrl flow on Lg.         (f < g)
    - Never interrupted by ctrl flow on Le.         (e ≤ f)
    - Sequentialized with other ctrl flow on Lf  (f > 0)
    - Preempted by other ctrl flow on Lf.           (f = 0)

![Untitled](week-9%2002089168bde14dc58fcce08ac876aea5/Untitled%202.png)

# Thread Synchronization

- Thread can be preemptes by any thread at any time(unpredicted)
    - any time : in oostubs program the timer, unpredict timer in the further.
    - any thread : of higher, same or lower priority(progress garantee)
    

### Thread Synchronization: Overview

- Goal (for the user): **Coordination of resource accesses**
    - Mutex : Coordinating exclusive access reusable resources
    - Semaphpre : Interacting with / coordinating consumable resources
- Implementation approach: **Coordination of CPU allocation of threads**
    - idea: exclude particular threads from scheduling for certain amount of time while we want to block them.
        - how can we make a thread wait for a resource to become free?→below

### Mutex – Mutual Exclusion

- Correctness condition : 0 ≤ ∑lock() – ∑unlock() ≤ 1
    - At every point in time, there is at maximum one thread in the critical section.

![Untitled](week-9%2002089168bde14dc58fcce08ac876aea5/Untitled%203.png)

- **Mutex: with Busy Waiting**
    - store state in boolean variable(0 free)
    - wait busily iin lock() until variable is 0
    
    ```cpp
    // __atomic_test_and_set is a gcc builtin for
    // (CPU specific) test-and-set
    class SpinningMutex {
     char locked;  //(0=free, 1=locked)
    public:
     SpinningMutex() : locked (0) {}
     void lock(){
     while (__atomic_test_and_set(
     &locked, __ATOMIC_RELAXED))
     ;
     }
     void unlock() {
     locked = 0;
     }
    };
    ```
    
    ```cpp
    lock:
    		 mov $1,%dl
    L2:  
    		 mov %edx,%eax
    		 xchg %al,(%rdi)
    		 test %al,%al   // if old value of lock is 1 continue loop
    		 jne L2
    		 ret
    unlock:
    		 movb $0, (%rdi)
    		 ret
    ```
    
    - this implementation: found locked → burn cpu cycles until time slices used up, because other thread is now hlólding the lock, it will release the lock until it done with the CS. it’ s not scheduled until we are done with time slices.
    - spinning : delay the other thread until we done with the work. → doesn’t suit for single core machine
    - **Assessment**
        - PROs
            - Maintains consistency, satisfies correctness condition
            - Synchronization without involving the OS
                - no syscall necessary
        - CONs
            - Busy waiting wastes a lot of CPU time
                - at least 1 time slice is used up
                - Scheduler may “penalize” thread
- **Mutex: with “Hard Synchronization”**
    
    ```cpp
    class HardMutex {
    public:
     void lock(){
     forbid(); // disable multitasking
     }
     void unlock(){
     permit(); // enable multitasking
     }
    };
    ```
    
    - Implementation of forbid() and permit()
        - e.g. in the scheduler
            - special, non-preemptible “real-time priority”
            - own priority level L¼ for the scheduler
            - resume() simply switches back to the caller
    - or simply on epilogue level
        
        ```cpp
        void forbid(){
         enter();
        }
        void permit(){
         leave();
        }
        ```
        
        - Context switching usually resides on epilogue level
            - Epilogue-level control flows are sequentialized
            - As long as a thread is on epilogue level, it cannot be preempted
        - Consequence: Sequentialization also with epilogues
    - Necessitates a way to disable preemption
    - **Assessment**
        - PROs
            - Maintains consistency, satisfies correctness condition
            - Simple to implement
        - CONs
            - Broadband effect
                - Across-the-board delay of all threads (and potentially even epilogues!)
            - Priority violation
                - delay control flows with higher priority
            - Pessimistic
                - We put up with the disadvantages, although the collision probability is very low.
        - Thread synchronization on epilogue level has many disadvantages. It is, however, appropriate for very short, seldomly entered critical sections – or if we need to synchronize with epilogues anyways.

### Passive Waiting

- Previously shown Mutex implementations are not ideal
    - Mutex with busy waiting: wastes CPU time
    - Mutex with hard synchronization: coarse-grained, violating priorities
- Better approach: Exclude thread from CPU scheduling as long as the mutex is locked
    - realize that lock is taken instead of testing again right away, call resume(). this will not used up the CPU time slices, but give the CPU to another thread that may make any progress and realize the lock.
- Mutex: with Passive Waiting
    - Threads can “wait passively” for an event
        - Wait passively → be excluded from CPU scheduling, when mutex is locked
        - New thread state: **waiting (for an event)**
    - Occurrence of an event triggers leaving the waiting state
        - Thread is included in CPU scheduling, when lock is unlocked
        - Thread state: **ready**
- Necessary abstractions:
    - Scheduler operations: block(), wakeup()
    - Synchronization object: **Waitingroom**
        - Synchronization object: Waitingroom
            - a queue of waitting threads
        
        ![Untitled](week-9%2002089168bde14dc58fcce08ac876aea5/Untitled%204.png)
        
- Scheduler operations
    - **block(Waitingroom& w)**
        - enqueue active thread (caller) in queue of synchronization object w
        - activate another thread (from ready list)
    - **wakeup(Customer& t)**
        - enqueue t in ready list
- Waitingroom operations
    - enqueue and dequeue.
    
    ```cpp
    class WaitingMutex : public Waitingroom {
     char locked;
    public:
     WaitingMutex() : locked(0) {}
     void lock() {
    		 while (__atomic_test_and_set(&locked, __ATOMIC_RELAXED))
    				 scheduler.block(*this);
    		 }
     void unlock() {
    		 locked = 0;
    		 // fetch possibly waiting thread and wake it up
    		 Customer *t = dequeue();
    		 if (t)
    		 scheduler.wakeup(*t); 
    		//still test if lock free , if not, block again
     }
    };
    ```
    
    - Why not wake all threads up?
        - all threads will been enqueued and test their lock statements, those thread with their lock statement locked while they were still in waitting room, which means they are still been locked. so they will been blocked again except the first one.
    - Do we really need TAS here?
        - **bigger Problem** : lock() and unlock() are critical sections themselves and Atomic TAS cannot solve it
            - we figure out lock is locked, enter loop body. just before we call block, there is context switch, other thread unlocks the lock, at some point we go back and still enter block
                - we block ourself althought the lock is free.
                - TAC is atomic but the block() operation should also be the part of the  CS. otherwise it may been blocked and nerve wakeup, since the unlock event has already happend.
    - approach:
    
    ```cpp
    class WaitingMutex : public Waitingroom {
     char volatile locked;
    public:
     WaitingMutex() : locked(0) {}
     void lock() {
    	 **mutex.lock();**
    	 while (locked == 1)
    	 scheduler.block(*this);
    	 locked = 1;
    	 **mutex.unlock();**
     }
     void unlock() {
    	 **mutex.lock();**
    	 locked = 0;
    	 // fetch possibly waiting thread and wake it up
    	 Customer *t = dequeue();
    	 if (t) scheduler.wakeup(*t);
    	** mutex.unlock();**
     }
    };
    ```
    
    - still this wattingmutex is recursive.
    - spinmutex works here
    - WORKS WITH A HARDMUTEX
        - protect lock() and unlock() on the epilogue level
    
    ```cpp
    class WaitingMutex : public Waitingroom {
     char volatile locked;
    public:
     WaitingMutex() : locked(0) {}
     void lock() {
     **enter();**
     while (locked == 1)
     scheduler.block(*this);
     locked = 1;
     **leave();**
     }
     void unlock() {
     **enter();**
     locked = 0;
     // fetch possibly waiting thread and wake it up
     Customer *t = dequeue();
     if (t) scheduler.wakeup(*t);
     **leave();**
     }
    };
    ```
    
    - when a thread is doing buffer modification, its time slice is used up and switch to another thread
    
    ![Untitled](week-9%2002089168bde14dc58fcce08ac876aea5/Untitled%205.png)
    
- mutex resides on epi level, after mutex locked it will go back L0, do some modification on the buffer on L0, after modification go to the epi level to unlock the mutex.
- in general : mutex resides on the same level as the scheduler.

![Untitled](week-9%2002089168bde14dc58fcce08ac876aea5/Untitled%206.png)

### Semaphore

- semaphore := synchronization object + counter
- prolaag(), P(), wait(), down(), acquire(), pend()
    - if counter > 0, decrease counter
    - if counter ≤ 0, wait until counter > 0 and retry
- verhoog(), V(), signal(), up(), release(), post()
    - increase counter
    - if counter = 1, wake up possibly waiting thread
- Semaphore vs. Mutex
    - Mutex is often understood as a two-valued semaphore
        - – Mutex Semaphore with initial counter value 1
        - lock() → P(), unlock() → V()
    - However, the semantics are different
        - A locked mutex (implicitly or explicitly) has an owner
            - Only this owner may call unlock()
            - Mutex implementations e.g. on Linux or Windows check this.
        - A mutex can (usually) also be locked recursively.
            - Internal counter: The same thread may call lock() multiple times; after a matching number of unlock() calls, the mutex is unlocked again.
        - In contrast, a semaphore can be incremented or decremented by any thread

# Synchronization Objects on Windows

- Windows takes the idea of waiting objects quite far
    - Every kernel object is also a synchronization object
        - explicit synchronization objects: Event, mutex, timer, semaphore
        - implicit synchronization objects: File, socket, thread, process, …
    - Waiting semantics depends on the object
        - Thread waits for “signaled” state
        - State is, if applicable, modified by successful waiting
        - e. g. wait for mutex object, the mutex becomes free
            - signaled
            - also state changed → now locked bur for your waitting thread
- Uniform system interface for all object types
    - Kernel object is represented by a HANDLE
    - WaitForSingleObject(hObject, dwMillisec
        - Wait for synchronization object with timeout
    - WaitForMultipleObjects(nCount, hObjects[], bWaitAll, dwMillisec)
        - Wait for one or more synchronization objects with timeout(“and”/“or” waiting, depending on bWaitAll = true/false)
    
    ![Untitled](week-9%2002089168bde14dc58fcce08ac876aea5/Untitled%207.png)
    

### Synchronization and Costs

- Synchronization objects are managed in the kernel
    - protect critical data structure
    - maintain consistency :Internal synchronization on epilogue level
- This can make their use very costly:
    - We need to switch to the kernel for each state change
    - User/kernel mode transitions are very expensive.
    - IA-32/x86-64: several hundred cycles!
- These costs are particularly pronounced for mutexes:
    - Usually u have a really short CS, The time needed for locking/unlocking mutexes is often a multiple of the time the critical section is locked.
    - Actual contention (thread wants to enter an already locked section) rarely occurs
- **Approach: Manage mutex as far as possible in user mode**
    - Minimize the normal-case cost
        - Normal case: critical section is free
        - Special case: critical section is locked
    - Introduce a fast path for the normal case
        - Test, locking and unlocking in user mode
            - Ensure consistency algorithmically / with atomic CPU instructions
            - only if we realized that mutex is lock, then go to the kernel to make kernel to block this thread that locks the mutex
        - Wait in kernel mode
            - We need the kernel for the transition to the passive waiting state
        - Further optimization for multiprocessor machines
            - Busily wait for limited amount time before waiting passively
            - High probability that the critical section is free before

# Summary

[Task-6](https://www.notion.so/Task-6-9352c222cd8a42189e39140bd6dec18f)