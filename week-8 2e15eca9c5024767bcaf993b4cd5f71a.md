# week-8

# **week-8**

- Course: OSC
- [Materials:](https://os.inf.tu-dresden.de/Studium/OSC/SS2022/L07-Threads.pdf)

# Kernel-Level Threads

- application been called as func calls
- Coroutine swith : syscall

![Untitled](week-8%202e15eca9c5024767bcaf993b4cd5f71a/Untitled.png)

![Untitled](week-8%202e15eca9c5024767bcaf993b4cd5f71a/Untitled%201.png)

![Untitled](week-8%202e15eca9c5024767bcaf993b4cd5f71a/Untitled%202.png)

- What will CPU automatly stores in stack when intr comes in, in order to resume the app1 where we left off?
    - PC of the instruction where we  just intruppted at.
- problem we have a ready list contains all coroutines we are ready to run, the process of modifying the list data structure should be seted in IH level
- **Thread Switch in the Epilogue**
    - A application explictly calls resume, before that we say enter, then we are in the resume implementation we solved before, save all NV-Rs, switch to another stack, load all NV-Rs and then return, this return returns to kickoff function. but u still have guard locked(at the brginning of resume). in kickoff need to make sure we leave kickoff again, right before we actually called application.
    - enter must corresponde leave!!

# Scheduling

## Classification

### Resource type **of the scheduled hardware resource**

- CPU scheduling
    - more process than cpu→multiplexed CPU for more than 1 P
    - waitting list requried
- I/O scheduling of the resource “device”, particularly “disk”
    - Device parameters and device state determine the next I/O operation
    - Scheduling decisions possibly not conforming to CPU scheduling → process with high priority cpu may end up in waiting list for long time.

### Operation mode of the controlled computer system

- Batch scheduling(in 50’ 60s)
    - for interation-less programs
    - non-preemptive scheduling
    (or preemptive scheduling with long time slices) → overhead of Context-switch minimization
- Interactive scheduling
    - for ineractiv Process
    - **Event-driven, preemptive** scheduling with short time slices
    - Partly response-time minimization by heuristics
- Real-time scheduling
    - Event- or time-driven **deterministic** scheduling
    - Guarantee of keeping environment-specific deadlines(e.g brake of the car )
    - Focus: **Timeliness**, not performance

### Point in time when the schedule is determined

- Online scheduling dynamic, **during** actual program
execution
    - runs on time, soft dead line(have ddl but won’t be make any damage when it been skiped e,g video player)
- Offline scheduling static, **before** actual program execution
    - If complexity prohibits scheduling at runtime
        - Guarantee keeping all ddl: NP-hard
        - **Critical** if we must react to any preventable catastrophic situation
    - **Result**: Complete schedule(Schedule Table)
        - Schedule Table: which point and which task is running on the CPU, if another task is running, the schedule will forcely remove such task.
        - **(Half) automatically** generated via source-code analysis of a specialized “compiler”
            - (Half) automatically : normally for spcialize compiler zou need to put some annotations, Program need to make sure those annotations are safe.(loop 4 times → annotation : max 4 times, compiler determine maximum times of excution )
            - compiler is capable to predict how long certain piece of code in task takes.
            - Often executed by a **time-triggered** scheduler
        - Usually limited to **hard real-time** systems
            - 

### Determinism of timing and duration of process runs

- Deterministic scheduling of **known, exactly pre-computed processes**
    - **KNOWN: runtimes and ddls**
    - Exact prediction of CPU load
    - System cannot give and enforce time guarantees
    - Time guarantees are valid regardless of system load
- Probabilistic scheduling of unknown processes
    - UNKNOWN: runtimes and ddls
    - (Probable) CPU load can only be estimated
    - System cannot give and enforce time guarantees
    - Timing guarantees conditionally achievable by application mechanisms(can only use some appl. mechanisum to keep ddls e.g temporarily raise the hierarchy)

### Cooperation behavior of (user/system) programs

- Cooperative scheduling of interdependent processes
    - Processes must **voluntarily yield the CPU** in favor of other processes
    - Program execution must (directly/indirectly) trigger **system calls**
    - **System calls** must (directly/indirectly) activate the **scheduler**
- Preemptive scheduling of independent processes
    - Processes are **forcibly deprived of the CPU** in favor of other processes
    - Events can trigger preemption of the running process

### Computer architecture of the system

- **Uni-processor scheduling**: **pseudo** parallel for multiprogramming/processing systems
- Multi-processor scheduling in shared-memory systems
    - Parallel process execution possible
    
    - All processors process **one global ready list**
        
        ![Untitled](week-8%202e15eca9c5024767bcaf993b4cd5f71a/Untitled%203.png)
        
        - **PRO**
            - Less synchronization costs
            - Better cache utilization cuz processes staz on the same CPU
        - **CON**
            - CPU can drain (empty list)
                - Solution: On-demand load balancing **(pull)**
                    - When a READY list is empty
                - By a load-balancer process **(push)**
    - Each processor processes its **local ready list**
        
        ![Untitled](week-8%202e15eca9c5024767bcaf993b4cd5f71a/Untitled%204.png)
        
        - pro
            - No CPU runs empty
        - con
            - Processes are not bound to particular CPUs
                - low cache utilization
            - Accesses to the READY list must be synchronized
                - Spinlock
                - Conflict probability grows with CPU count!

### Decision-making level when scheduling resources

- Long-term scheduling controls the degree of
multiprogramming
- Medium-term scheduling as part of swapping
- Short-term scheduling schedules processes on the CPU(s)

## in Windows

### Processes and Threads in Windows NT

![Untitled](week-8%202e15eca9c5024767bcaf993b4cd5f71a/Untitled%205.png)

- each thread has its own set of regs and stack, all threads have common code segment and data segment
- **Process**: Environment and address space for threads
    - A Win32 process always contains at least one thread
    - **Thread**: Code-executing entity
    - Thread implementation by NT kernel
    - Scheduler assigns processing time to threads
- **The NT Scheduler**
    - Preemptive, priority-based scheduling
        - thread with higher prio. preempts thread with lower prio.
        - Round-Robin for threads with same priority
            - assignment of one time slice (“Quantum”)
    - Thread priorities
        - 0 to 31, subdivided in three ranges
            - Variable Priorities: 1 to 15
            - Real-time Priorities: 16 to 31
            - Priority 0 is reserved for the Zero-Page Thread
        - Threads of the Executive maximally use priority 23, with higher prio the thread will preempts kernel threads.
    - **Time Slice (Quantum)**
        
        ![Untitled](week-8%202e15eca9c5024767bcaf993b4cd5f71a/Untitled%206.png)
        
        - Quantum is decreased by 3 at every clock tick (every 10 or 15 ms) or by 1 if the thread voluntarily enters a waiting state(resume()  or yield CPU)
        - server system has fixed quantum (36)
    - **Priority Classes, Relative Thread Priority**
        
        ![Untitled](week-8%202e15eca9c5024767bcaf993b4cd5f71a/Untitled%207.png)
        
    - Priorities: Variable Priorities
        - Thread priority = Process priority class + Thread priority + Boost
    
    - Priorities: Realtime Priorities
        - Pure priority-based Round-Robin
            - Special user privilege necessary (SeIncreaseBasePriorityPrivilege)
            - Operating system itself can be negatively affected cuz you can create a thread whith higher prio than kernel thread
        - Thread priority = REALTIME_PRIORITY_CLASS + Thread priority
    - Dynamic Priority Boosts
        - The system dynamically raises thread priorities in specific situations (not for REALTIME_PRIORITY_CLASS)
        - Dynamic Boost gets “used up” (one level per Quantum)
    - Selecting the Next Thread (SMP)
        - goal is to achieve ”fair” Round-Robin at maximum throughput.
        - Problem: Cache effects
        - base on Affinity (mapping of CPUs to thread):
            - hard_affinity:  PIN 1 thread to a cpu
            - ideal_processor: if possible i want to run this Thread in CPU
            - soft_affinity: recall the thread run before
            - last_run : Point in time the thread ran last
            - measure the starvation of the process
        - Algo :: CPU n calls FindReadyThread()
            - Pick highest-prioritized non-empty ready list
            - Search this ready list for a thread with
                
                ![Untitled](week-8%202e15eca9c5024767bcaf993b4cd5f71a/Untitled%208.png)
                
            - otherwise pick head of this ready list
            
            iit has run long in last
            
            ![Untitled](week-8%202e15eca9c5024767bcaf993b4cd5f71a/Untitled%209.png)
            
    - Changes in Windows 2003
        - One ReadyQueue per CPU,
        - Algorithm: CPU n calls FindReadyThread()
            - Pick highest-prioritized non-empty ready list of CPU n
            - Pick head of this ready list
            - If ReadyQueue completely empty, activate Idle Loop
            - In Idle-Loop: Search ReadyQueue of other CPUs

## in Linux

### Linux Tasks …

- are the Linux-Kernel abstraction for …
    - UNIX processes: one thread in one address space
    - Linux Threads: special process that shares its virtual address space with at least one other thread
- are the activities considered by the scheduler

### Linux’ Modular Scheduler

![Untitled](week-8%202e15eca9c5024767bcaf993b4cd5f71a/Untitled%2010.png)

![Untitled](week-8%202e15eca9c5024767bcaf993b4cd5f71a/Untitled%2011.png)

![Untitled](week-8%202e15eca9c5024767bcaf993b4cd5f71a/Untitled%2012.png)

# task 5

## Time slice Scheduler

- Goal: protect critical section OS using the prolog/epilogue model
- Scheduler : Timer interrupts trigger thread preemption
- Calling guard-protected methods of the scheduler:
    - Scheduler variable is now change to Guarded_Scheduler

## Preemptive Thread Switch

![Untitled](week-8%202e15eca9c5024767bcaf993b4cd5f71a/Untitled%2013.png)

## Thread Switch in epilogue

- Tips
    - Never call enter from the epilogue (double request)
    - Basic rule (see above) also holds for the first thread activation(!)
        - Kickoff function is expcected to be called with gaurd locked. so before another thread is running we need to make sure to release the guard lock.
        - similar in main() : before call scheduler.scheduler() → make sure guard is locked  before schedule is running. cuz this will run the first application and release the lock
        - **summary** : every require needs some matching release.
    - 

## Class Guarded_Scheduler

- C++ detail:
    - Because methods of Guarded_Scheduler have the same names asthose of the base class Scheduler, they hide them
    - Access hidden methods: explicitly provide **base-class scope** when calling a method
    
    ```cpp
    Guarded_Scheduler scheduler;
    Application appl1, appl2;
    scheduler.ready (appl1); // Guarded_Scheduler method
    scheduler.Scheduler::ready (appl2); // Scheduler method
    ```
    
- Programming the 8254
    
    // |   bits   |   value  |  meaning
    // |    0      |     0      |  Binary counting of 16 bits
    // |    1-3   |    010   |  Periodic interrupt
    // |    4-5   |     11   |  Low-order, then high-order counte byte
    // |    6-7   |     00   |  Counter 0
    // 7 6 5 4 3 2 1 0
    // 0 0 1 1 0 1 0 0  = 52 = 0x34
    

## Preemptive Scheduling

- Thread A uses the CPU for 18 ms and then voluntarily calls resume()
- Thread B continuously uses the CPU and never voluntarily yields

![Untitled](week-8%202e15eca9c5024767bcaf993b4cd5f71a/Untitled%2014.png)

- solution :
    - reset the timer at first resume(): Thread B get full time slice.
    - RR or VRR